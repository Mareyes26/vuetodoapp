{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2ee0e5-c9df-4aac-b93c-08ce104d43b7",
   "metadata": {},
   "source": [
    "<img src=\"https://www.unad.edu.co/images/footer/logo-unad-acreditacion-min.png\" width=\"780\" height=\"140\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef162f3-7595-44ef-88ff-821db9fc4c5e",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">Curso: ENSEMBLE METHODS AND KERNELS</p>\n",
    "\n",
    "<p style=\"text-align: center;\"> Código Curso: 203008076A_2031</p>\n",
    "\n",
    "<p style=\"text-align: center;\"> Grupo: 203008076_5</p>\n",
    "\n",
    "<p style=\"text-align: center;\">  Phase 2 - Getting Started with Ensemble Learning and Non-Generative Methods – Theory</p>\n",
    "\n",
    "<p style=\"text-align: center;\">  Presentado por: Maria Del Mar Reyes Agudelo </p>\n",
    "\n",
    "<p style=\"text-align: center;\"> Código: 1143409106</p>\n",
    "\n",
    " <p style=\"text-align: center;\">  Tutor(a): Jorge Luís Quintero </p>\n",
    "\n",
    " <p style=\"text-align: center;\"> UNIVERSIDAD NACIONAL ABIERTA Y A DISTANCIA - UNAD </p>\n",
    "\n",
    "<p style=\"text-align: center;\"> 2025</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc214b1-ec21-4d3c-89e1-295250a9a053",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Exercise 1: Metrics description of the exercise:\n",
    "\n",
    "Calculate the Accuracy, Precision, Recall, and F1 Score metrics based on the confusion matrix in the letter choice, which we assume comes from a prediction model of a variable in a dataset. Explain what the results mean:\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d0b96",
   "metadata": {},
   "source": [
    "Accuracy: Proportion of correct predictions over the total number of cases.\n",
    "\n",
    " Accuracy=  (150+170)/(150+170+25+75)≈0.762(76.2%)\n",
    "\n",
    "The model has an accuracy of 76.2%, meaning it correctly classifies most cases in the dataset. However, accuracy alone is not always a reliable indicator of performance, especially if the dataset is imbalanced. While the model appears to perform well overall, it is essential to analyze other metrics to gain a more comprehensive understanding of its effectiveness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53338c83",
   "metadata": {},
   "source": [
    "Precision: Proportion of true positives out of all predicted positives.\n",
    " \n",
    "Precision=  150/(150+25)≈0.857(85.7%)\n",
    "\n",
    "he model's precision is 85.7%, indicating that when it predicts a positive outcome, it is correct most of the time. This is crucial in applications where false positives can be costly. A high precision value suggests that the model has a low false positive rate, meaning its positive predictions are generally reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18728e",
   "metadata": {},
   "source": [
    "Recall (Sensitivity): Proportion of true positives out of all actual positives.\n",
    "\n",
    "Recall=  150/(150+75)≈0.667 (66.7%)\n",
    "\n",
    "Recall is 66.7%, meaning the model correctly identifies only two-thirds of the actual positive cases. This can be problematic in scenarios where missing a positive case has serious consequences. A low recall indicates that the model is failing to detect a significant number of positive cases, which may require adjustments in decision thresholds or training strategies to improve sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d57c8f6",
   "metadata": {},
   "source": [
    "F1-Score: Harmonic mean between precision and recall.\n",
    "\n",
    "F1=2 X  (0.857 X 0.667)/(0.857+ 0.667)≈ 0.75 (75%)\n",
    "\n",
    "The F1-score, which balances precision and recall, is 75%. This value suggests that the model maintains a reasonable balance between both aspects, although the lower recall indicates room for improvement. In applications where it is important not only to avoid false positives but also to minimize false negatives, improving recall without sacrificing too much precision should be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3904412-eb75-4319-9a0c-d7ab8667e371",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = 170 #True_Negatives\n",
    "FP = 25 #False Positives\n",
    "FN = 75 #False Negatives\n",
    "TP = 150 #True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d062e32b-683f-41e9-aa9e-e489ad8d9350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "#Proportion of correct predictions over the total number of cases.\n",
    "Exactitud=(TP + TN)/(TP + TN + FP + FN)\n",
    "print(Exactitud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cd4178d-398a-4f56-a47b-ac4c736fbe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#Proportion of true positives out of all predicted positives.\n",
    "Precision=TP/(TP + FP)\n",
    "print(Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3094e0-02db-410f-b7a6-025c16b39e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "#Proportion of true positives out of all actual positives.\n",
    "Recall=TP/(TP + FN)\n",
    "print(Recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "401e7854-3db2-489e-b128-a7f477cbfe8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#Harmonic mean between precision and recall.\n",
    "F1_Score= 2*(Precision*Recall/(Precision+Recall))\n",
    "print(F1_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729dd1c-6550-408a-888c-63055796336f",
   "metadata": {},
   "source": [
    "### Exercise 2: Validation and Learning of Curves\n",
    "\n",
    "In the file Appendix - 1 learning_curve.ipynb shared in the forum of Phase 2, in a markdown cell write with your words what is the importance of the validation and learning curves and what information they give us and then develop with the file the learning curve with the information given in the chosen item. The dataset must be loaded from the scikit-learn library using the fetch_openml. Explain the results of the curve:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654bf829-857f-496c-842a-316afd9462b2",
   "metadata": {},
   "source": [
    "E: Import the dataset CPMP-2015-regression (ID:41700) for Regression and diabetes (ID:37) for Classification. Present the learning curve of the dataset using a linear and logistic regression model respectively, taking the training size with 12 samples (train_sizes=np.linspace(0.1, 1.0,12)). Interpret your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b5356109-1da3-4f5d-b25a-c4fc03bd39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import warnings\n",
    "import openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "68c3c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression with dataset  CPMP-2015-regression (ID:41700)\n",
    "\n",
    "# Cargar el dataset  CPMP-2015-regression de OpenML para regresión\n",
    "dataset_regression = openml.datasets.get_dataset(41700) #import \n",
    "X_kin, y_kin, _, _ = dataset_regression.get_data(target=dataset_regression.default_target_attribute)  # Datos de entrada\n",
    "y_kin = y_kin.astype(np.float64)  # Convertir a tipo float para regresión\n",
    "\n",
    "# Crear el modelo: Regresión Lineal\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Definir los tamaños de entrenamiento: 9 valores de 10% a 100% del total\n",
    "train_sizes = np.linspace(0.1, 1.0, 12) #Tal como fue la instrucción..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb11a909",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kin[\"instance_id\"] = LabelEncoder().fit_transform(X_kin[\"instance_id\"])\n",
    "X_kin[\"algorithm\"] = LabelEncoder().fit_transform(X_kin[\"algorithm\"])\n",
    "X_kin[\"runstatus\"] = LabelEncoder().fit_transform(X_kin[\"runstatus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3a289a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizar validación cruzada K-Fold (para regresión se utiliza KFold)\n",
    "cv_reg = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Calcular las learning curves para el modelo de regresión\n",
    "train_sizes_kin, train_scores_kin, valid_scores_kin = learning_curve(\n",
    "    lin_reg, X_kin, y_kin, train_sizes=train_sizes, cv=cv_reg, scoring=\"r2\", random_state=42\n",
    ")\n",
    "\n",
    "# Calcular la media y desviación estándar de los scores\n",
    "train_scores_mean_kin = np.mean(train_scores_kin, axis=1)\n",
    "train_scores_std_kin = np.std(train_scores_kin, axis=1)\n",
    "valid_scores_mean_kin = np.mean(valid_scores_kin, axis=1)\n",
    "valid_scores_std_kin = np.std(valid_scores_kin, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f018fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Graficar la learning curve para regresión\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes_kin, train_scores_mean_kin, 'o-', color=\"purple\", label=\"Score de entrenamiento (R2)\")\n",
    "plt.plot(train_sizes_kin, valid_scores_mean_kin, 'o-', color=\"green\", label=\"Score de validación (R2)\")\n",
    "plt.fill_between(train_sizes_kin, train_scores_mean_kin - train_scores_std_kin,\n",
    "                 train_scores_mean_kin + train_scores_std_kin, alpha=0.2, color=\"purple\")\n",
    "plt.fill_between(train_sizes_kin, valid_scores_mean_kin - valid_scores_std_kin,\n",
    "                 valid_scores_mean_kin + valid_scores_std_kin, alpha=0.2, color=\"pink\")\n",
    "plt.title(\"Learning Curve - Regresión (Dataset_regression)\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Score (R2)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6f094f",
   "metadata": {},
   "source": [
    "#### Interpretación\n",
    "\n",
    "Como vemos en la grafica, se identifica que el score de validacion al principio de la regression tiene una validacion como vemos toma una curva muy baja, despues va tomando la misma linea que el score de entrenamiento, este caso indica que el modelo es un Overfitting ya que esta memorizando el set de entremiento, pero no esta aprendiendo, ya que llega un momento en que el score de validacion se sobre ajusta los parametros al score de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430e2fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 2. Clasification with dataset diabetes (ID:37)\n",
    "\n",
    "# Cargar el dataset diabetes de OpenML para clasificación\n",
    "diabetes = fetch_openml(data_id=37, as_frame=True)\n",
    "X_qsar = diabetes.data\n",
    "y_qsar = diabetes.target  # La variable target puede estar codificada como strings o categorías\n",
    "\n",
    "# Crear el modelo: Regresión Logística para clasificación\n",
    "# Se establece un máximo de iteraciones para asegurar la convergencia.\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Para clasificación, se usa StratifiedKFold para mantener la proporción de clases\n",
    "cv_clf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Calcular las learning curves para el modelo de clasificación\n",
    "train_sizes_qsar, train_scores_qsar, valid_scores_qsar = learning_curve(\n",
    "    log_reg, X_qsar, y_qsar, train_sizes=train_sizes, cv=cv_clf, scoring=\"accuracy\"\n",
    ")\n",
    "\n",
    "# Calcular la media y desviación estándar de los scores\n",
    "train_scores_mean_qsar = np.mean(train_scores_qsar, axis=1)\n",
    "train_scores_std_qsar = np.std(train_scores_qsar, axis=1)\n",
    "valid_scores_mean_qsar = np.mean(valid_scores_qsar, axis=1)\n",
    "valid_scores_std_qsar = np.std(valid_scores_qsar, axis=1)\n",
    "\n",
    "# Graficar la learning curve para clasificación\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(train_sizes_qsar, train_scores_mean_qsar, 'o-', color=\"orange\", label=\"Score de entrenamiento (accuracy)\")\n",
    "plt.plot(train_sizes_qsar, valid_scores_mean_qsar, 'o-', color=\"g\", label=\"Score de validación (accuracy)\")\n",
    "plt.fill_between(train_sizes_qsar, train_scores_mean_qsar - train_scores_std_qsar,\n",
    "                 train_scores_mean_qsar + train_scores_std_qsar, alpha=0.2, color=\"orange\")\n",
    "plt.fill_between(train_sizes_qsar, valid_scores_mean_qsar - valid_scores_std_qsar,\n",
    "                 valid_scores_mean_qsar + valid_scores_std_qsar, alpha=0.2, color=\"g\")\n",
    "plt.title(\"Learning Curve - Clasificación (Diabetes)\")\n",
    "plt.xlabel(\"Tamaño del conjunto de entrenamiento\")\n",
    "plt.ylabel(\"Score (accuracy)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc4bfa-76d9-4e08-b4f7-e4463121c065",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_kin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c4ca4-20fe-42c5-9955-daa72342f1ff",
   "metadata": {},
   "source": [
    "#### Interpretación\n",
    "\n",
    "En el dataset de diabetes se identifica que la clasificacion tien un buen ajuste(Good fit),como vemos el score de entrenamiento y validadcion son similares, generaliza bien los nuevos datos sin caer en sobreajuste ni subajuste.A pesar que al inicio habia una mayor diferencia entre ambas curvas, a medida que el score de entrenamiento aumenta, la brecha se redujo, reflejando una mejora de rendimiento del modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666afbe",
   "metadata": {},
   "source": [
    "### Exercise 3: Voting and Stacking Methods and non-generative metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3651e186-8d25-4156-b6da-430a7acdd698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de modelos usando validación cruzada:\n",
      "Bagging: Precisión promedio = 0.67, Desviación estándar = 0.06\n",
      "Boosting (AdaBoost): Precisión promedio = 0.71, Desviación estándar = 0.05\n",
      "Random Forest: Precisión promedio = 0.69, Desviación estándar = 0.03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar el dataset de diabetes\n",
    "# Nota: Este dataset es continuo, pero lo simplificaremos para clasificación binaria\n",
    "data = load_diabetes()\n",
    "X = data.data\n",
    "y = (data.target > 140).astype(int)  # Clasificación binaria: 1 si target > 140, 0 en caso contrario\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear los modelos\n",
    "bagging_model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    n_estimators=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "boosting_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(max_depth=1, random_state=42),  # Árboles débiles\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_forest_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Lista de modelos para comparar\n",
    "models = {\n",
    "    \"Bagging\": bagging_model,\n",
    "    \"Boosting (AdaBoost)\": boosting_model,\n",
    "    \"Random Forest\": random_forest_model\n",
    "}\n",
    "\n",
    "# Comparar modelos usando validación cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"Comparación de modelos usando validación cruzada:\")\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "    print(f\"{name}: Precisión promedio = {scores.mean():.2f}, Desviación estándar = {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar modelos usando validación cruzada\n",
    "model_names = []\n",
    "train_scores = []\n",
    "valid_scores = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    ts, tsc, vsc = learning_curve(model, X_train, y_train, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "    model_names.append(name)\n",
    "    train_scores.append(tsc)\n",
    "    valid_scores.append(vsc)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72df86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(model_names)):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(ts,  np.mean(train_scores[i], axis=1), 'o-', label=f\"{model_names[i]} (train)\")\n",
    "    plt.plot(ts, np.mean(valid_scores[i], axis=1), 'o-', label=f\"{model_names[i]} (valid)\")\n",
    "    plt.ylim(0, 1.5)\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
